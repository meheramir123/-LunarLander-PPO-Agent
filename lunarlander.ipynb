{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd3ca53",
   "metadata": {},
   "source": [
    "Basic Random Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6102a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Meher\\Desktop\\lunar lander\\.venv\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "# Import Gym\n",
    "import gymnasium as gym\n",
    "\n",
    "# Create LunarLander Environment\n",
    "env = gym.make(\"LunarLander-v3\", render_mode='human')\n",
    "\n",
    "# Reset the environment to start\n",
    "observation, info = env.reset()\n",
    "\n",
    "# Run for 1000 steps with random actions\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()  # Random action\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    if terminated or truncated:  # If landed or crashed, reset\n",
    "        observation, info = env.reset()\n",
    "\n",
    "# Close the environment window\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba42551",
   "metadata": {},
   "source": [
    "Precision Reward Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0815994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import Wrapper\n",
    "\n",
    "# Custom wrapper to reward more precise landings\n",
    "class PrecisionLandingWrapper(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        # If the lander has finished (landed or crashed)\n",
    "        if terminated:\n",
    "            x_pos = obs[0]  # Horizontal position from center\n",
    "\n",
    "            # Reward adjustments based on how centered the landing is\n",
    "            if abs(x_pos) < 0.05:\n",
    "                reward += 100  # Perfect landing bonus\n",
    "            elif abs(x_pos) < 0.1:\n",
    "                reward += 50   # Good landing bonus\n",
    "            elif abs(x_pos) < 0.2:\n",
    "                reward += 5    # Okay landing bonus\n",
    "            else:\n",
    "                reward -= 50   # Penalty for poor landing\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddbdec6",
   "metadata": {},
   "source": [
    "Training the Agent with PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34630d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Create the training environment with the custom wrapper\n",
    "train_env = PrecisionLandingWrapper(\n",
    "    gym.make(\"LunarLander-v3\", \n",
    "             continuous=False, \n",
    "             gravity=-10.0,\n",
    "             enable_wind=False,\n",
    "             wind_power=15.0, \n",
    "             turbulence_power=1.5)\n",
    ")\n",
    "\n",
    "# Initialize the PPO model with MLP (neural net) policy\n",
    "model = PPO(\"MlpPolicy\", train_env, verbose=1)\n",
    "\n",
    "# Start training the agent\n",
    "model.learn(total_timesteps=200000, log_interval=50)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"ppo_lunar_lander\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50875e6f",
   "metadata": {},
   "source": [
    "Testing the Trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved PPO model\n",
    "model = PPO.load(\"ppo_lunar_lander\")\n",
    "\n",
    "# Create a test environment with render enabled\n",
    "test_env = gym.make(\"LunarLander-v3\", \n",
    "                    continuous=False, \n",
    "                    gravity=-10.0,\n",
    "                    enable_wind=False,\n",
    "                    wind_power=15.0, \n",
    "                    turbulence_power=1.5,\n",
    "                    render_mode='human')\n",
    "\n",
    "# Reset environment for testing\n",
    "obs, info = test_env.reset()\n",
    "\n",
    "# Run testing loop\n",
    "for _ in range(5000):\n",
    "    action, _states = model.predict(obs, deterministic=True)  # Use trained model to select action\n",
    "    obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        obs, info = test_env.reset()\n",
    "\n",
    "# Close rendering window\n",
    "test_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
